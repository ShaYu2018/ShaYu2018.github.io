---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<!-- Sidebar/menu -->
<div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
  <a href="#home" class="w3-bar-item w3-button">üè° Home</a>
  <a href="#news" class="w3-bar-item w3-button">üì∞ News</a>
  <a href="#researches" class="w3-bar-item w3-button">üîç Researches</a>
  <a href="#experiences" class="w3-bar-item w3-button">üíº Experiences</a>
  <a href="#educations" class="w3-bar-item w3-button">üìñ Educations</a>
  <a href="#publications" class="w3-bar-item w3-button">üìö Publications</a>
  <a href="#projects" class="w3-bar-item w3-button">üß∞ Projects</a>
  <a href="#award" class="w3-bar-item w3-button">üèÜ Awards</a>
</div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">üë®‚ÄçüéìYu</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>‚â°</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:157px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
<div class="w3-container w3-center w3-padding-32" id="home">
  <img style="width: 100%;max-width: 320px" alt="profile photo" src="figs/YuSha.jpg">
    <h1>Yu Sha</h1>
    <p class="w3-center">
      üè´ The Chinese University of Hong Kong | üìç Shenzhen, China
    </p>
    <p class="w3-center">
      üá®üá≥‚ùÑÔ∏è| ‚ôÇÔ∏è | 9Ô∏è‚É£6Ô∏è‚É£ | üê≠ | ‚ôä 
    </p>
    <p class="w3-center">
     üí™ | üì∏ | üèì 
    </p>
      <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:750px">
        I am Yu Sha (ü¶àÊ≤ôÊØìü¶à), now a Postdoctoral Researcher at <a style="color: #447ec9" href="https://www.cuhk.edu.cn/zh-hans">The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen)</a>. During 2019 to 2025, I am a PhD student at <a style="color: #447ec9" href="https://www.xidian.edu.cn/">Xidian University</a>, where I was co-advised by Prof. <a style="color: #447ec9" href="https://web.xidian.edu.cn/liubo/index.html">Bo Liu</a></a> and Prof. <a style="color: #447ec9" href="https://faculty.xidian.edu.cn/GSP2/zh_CN/index/335507/list/index.htm">Shuiping Gou</a></a>. During 2020 to 2022, I am a visiting scientist in <a style="color: #447ec9" href = "https://www.fias.science/en/theoretical-sciences/research-groups/kai-zhou/">"Deepthinkers"</a> group at 
        <a style="color: #447ec9" href="https://fias.institute/en/">Frankfurt Institute for Advanced Studies (FIAS)</a>, where I was co-advised by Prof. <a style="color: #447ec9" href="https://www.fias.science/en/fellows/detail/stoecker-horst/">Horst St√∂cker</a></a> and Prof. <a style="color: #447ec9" href="https://www.fias.science/en/fellows/detail/zhou-kai/">Kai Zhou</a></a>. In addition, during 2020 to 2025, I am a member of Xidian-FIAS Joint Research Center (XFJRC) and Giersch Science Center (GSC). My research interests includes AI in Industry (especially AI for acoustic damage detection and diagnosis, etc.), 
        AI in Physics (especially traditional filters with deep learning) and Deep Learning (especially Knowledge-guided DL, generative models and attention mechanisms). Before that, I received the B.Sc degree from <a style="color: #447ec9" href="https://www.lut.edu.cn/">Lanzhou University of Technology</a> in 2019.
      </p>
      <p class="w3-center">
        <a href="mailto:yusha@stu.xidian.edu.cn"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i>Email</a> &nbsp/&nbsp
        <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=e5ng8m0AAAAJ"><i class="fas fa-fw fa-graduation-cap"></i>Google Scholar</a> &nbsp/&nbsp
        <a href="https://orcid.org/0000-0003-4521-2077"><i class="fa fa-fw fa-address-card" aria-hidden="true"></i>ORCID</a>&nbsp/&nbsp
      </p>
      </tbody></table>
  </div>

<!-- The News Section -->
<!-- The News Section -->
<div class="w3-container w3-padding-32" id="news">
  <h2>üì∞ News</h2>
  <div id="news-container" style="height: 300px; overflow: hidden; position: relative;">
    <ul id="news-list" style="position: absolute; width: 70%;">
      <li><em>01/08/2025</em>, üì¢üì¢ I joined  <a style="color: #447ec9" href="https://www.cuhk.edu.cn/zh-hans">The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen)</a> as a Postdoctoral Researcher.</li>
      <li><em>17/06/2025</em>, üì¢üì¢ I obtained PhD degree from <a style="color: #447ec9" href="https://www.xidian.edu.cn/">Xidian University (XDU)</a>.</li>
      <li><em>03/03/2025</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://www.frontiersin.org/journals/neuroscience">Frontiers in Neuroscience</a>.</li>
      <li><em>29/11/2024</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221020">IEEE Journal of Biomedical and Health Informatics (JBHI)</a>.</li>
      <li><em>19/08/2024</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://www.sciencedirect.com/journal/expert-systems-with-applications">Expert Systems with Applications (ESWA)</a>.</li>
      <li><em>17/05/2024</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://kdd2024.kdd.org/">ACM SIGKDD 2024 (CCF-A)</a>.</li>
      <li><em>16/08/2023</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://link.springer.com/journal/11633">Machine Intelligence Research</a>.</li>
      <li><em>01/12/2022</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://www.sciencedirect.com/journal/artificial-intelligence-in-geosciences">Artificial Intelligence in Geosciences (AIG)</a>.</li>
      <li><em>30/09/2022</em>, üì¢üì¢ I came back to <a style="color: #447ec9" href="https://www.xidian.edu.cn/">Xidian University (XDU)</a> as a PhD visiting student.</li>
      <li><em>01/08/2022</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://opg.optica.org/conference.cfm?meetingid=63&yr=2022">Digital Holography and Three-Dimensional Imaging 2022</a>.</li>
      <li><em>19/05/2022</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://kdd.org/kdd2022/">ACM SIGKDD 2022 (CCF-A)</a>.</li>
      <li><em>19/04/2022</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://www.sciencedirect.com/journal/engineering-applications-of-artificial-intelligence">Engineering Applications of Artificial Intelligence (EAAI)</a>.</li>
      <li><em>06/04/2022</em>, üöÄüöÄ one paper has been uploaded to <a style="color: #447ec9" href="https://arxiv.org/">arXiv</a>.</li>
      <li><em>01/03/2022</em>, üöÄüöÄ two papers have been uploaded to <a style="color: #447ec9" href="https://arxiv.org/">arXiv</a>.</li>
      <li><em>10/02/2022</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://www.sciencedirect.com/journal/measurement">Measurement</a>.</li>
      <li><em>30/09/2020</em>, üì¢üì¢ I went to <a style="color: #447ec9" href="https://fias.institute/en/">Frankfurt Institute for Advanced Studies (FIAS)</a> as a PhD visiting student.</li>
      <li><em>10/09/2019</em>, üì¢üì¢ I was admitted to <a style="color: #447ec9" href="https://www.xidian.edu.cn/">Xidian University (XDU)</a> as a Fast-Track PhD student.</li>
    </ul>
  </div>
</div>

<style>
    #news-container {
    width: 88%;
  }
  
  #news-list {
    list-style-type: none;
    padding: 0;
    margin: 0;
    animation: scroll 15s linear infinite;
  }
  
  #news-list li {
    padding: 10px 0;
    border-bottom: 1px solid #eee;
  }
  
  #news-list li:last-child {
    border-bottom: none;
  }
  
  @keyframes scroll {
    0% {
      transform: translateY(0);
    }
    100% {
      transform: translateY(calc(-100% + 400px));
    }
  }
  
  #news-container:hover #news-list {
    animation-play-state: paused;
  }
</style>

<script>
  // Á°Æ‰øùÂÜÖÂÆπË∂≥Â§üÈïø‰ª•ÊªöÂä®
  document.addEventListener('DOMContentLoaded', function() {
    const newsList = document.getElementById('news-list');
    const container = document.getElementById('news-container');
    
    // Â§çÂà∂ÂàóË°®ÂÜÖÂÆπ‰ª•ÂàõÂª∫ËøûÁª≠ÊªöÂä®ÊïàÊûú
    if (newsList.scrollHeight > container.clientHeight) {
      newsList.innerHTML += newsList.innerHTML;
    }
    
    // Ë∞ÉÊï¥Âä®ÁîªÊó∂Èó¥Âü∫‰∫éÂÜÖÂÆπÈïøÂ∫¶
    const duration = newsList.scrollHeight / 50; // Ë∞ÉÊï¥Èô§Êï∞ÊéßÂà∂ÈÄüÂ∫¶
    newsList.style.animationDuration = duration + 's';
  });
</script>


<!-- The Researches Section -->
<!-- class="w3-container w3-light-grey w3-padding-32" -->
<div class="w3-container w3-padding-32" id="researches">
  <h2>üîç Researches</h2>
  <!-- <ul>
      <li><strong>Analysis of battlefield situation of artificial intelligence in the context of big data</strong></li>
  </ul> -->
  <ul>

    <li><h5>AI in Industry</h5>
      <ul>
        <li>Supervised learning for acoustic damage detection and diagnosis [<a style="color: #447ec9" href="https://www.sciencedirect.com/science/article/pii/S0957417424020220">1</a>, <a style="color: #447ec9" href="https://www.sciencedirect.com/science/article/pii/S0952197622001361">2</a>, <a style="color: #447ec9" href="https://dl.acm.org/doi/abs/10.1145/3637528.3671610">3</a>];</li>
        <li>Unsupervised learning for acoustic signal anomalous sound detection [<a style="color: #447ec9" href="https://dl.acm.org/doi/abs/10.1145/3534678.3539133">4</a>].</li>
      </ul>
    </li>

    <li><h5>Knowledge Guided AI</h5>
      <ul>
        <li>Physics knowledge-guided deep learning [<a style="color: #447ec9" href="https://dl.acm.org/doi/abs/10.1145/3637528.3671610">5</a>, <a style="color: #447ec9" href="https://www.sciencedirect.com/science/article/abs/pii/S0957417424020220">6</a>].</li>
      </ul>
    </li>
  </ul>
</div>

<!-- The Experiences Section -->
<div class="w3-container w3-padding-32" id="experiences">
  <h2>üíº Experiences</h2>
    <p><li> <em>08/2025 - now</em>, <strong>Postdoctoral Researcher</strong>, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China.</li></p>
    <p><li> <em>09/2020 - 06/2025</em>, <strong>PhD Vising Student</strong>, Xidian-FIAS Joint Research Center (XFJRC), Germany.</li></p>
    <p><li> <em>09/2020 - 06/2025</em>, <strong>PhD Vising Student</strong>, Giersch Science Center (GSC), Germany.</li></p>
    <p><li> <em>09/2020 - 10/2022</em>, <strong>PhD Vising Student</strong>, Frankfurt Institute for Advanced Studies (FIAS), Germany.</li></p>
    <p><li> <em>09/2019 - 06/2025</em>, <strong>PhD Student</strong>, School of Artificial Intelligence, Xidian University (XDU), China.</li></p>
</div>

<!-- The Educations Section -->
<div class="w3-container w3-padding-32" id="educations">
  <h2>üìñ Educations</h2>
    <p><li> <em>09/2019 - 06/2025</em>, School of Artificial Intelligence, Xidian University (XDU), China.</li></p>
    <p><li> <em>09/2015 - 06/2019</em>, School of Science, Lanzhou University of Technology (LUT), China.</li></p>
</div>

<!-- The Publications Section -->
<div class="w3-container w3-padding-32"" id="publications">
  <h2>üìö Publications</h2>
    <!-- <p class="w3-left-align" style="line-height:200%">
    I'm interested in devleoping <strong>efficient models</strong> for computer vision (e.g. classification, detection, and super-resolution) using pruning, quantization, distilaltion, NAS, etc.
    </p> -->
      <h4> Papers:</h4>
      <ol>
        <!-- 11 -->
        <div class="container">
          <div style="display: flex; align-items: flex-start; position: relative;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    KDD 2024 (Oral&Poster)
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/KDD2024.png' alt="sym" width="370" height="180" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>Hierarchical Knowledge Guided Fault Intensity Diagnosis of Complex Industrial Systems</strong>
                <br>
                <strong>Yu Sha</strong>, Shuiping Gou, Bo Liu, Ningtao Liu, Johannes Faber, Stefan Schramm, Horst Stoecker, Thomas Steckenreiter, Domagoj Vnucec, Nadine Wetzstein, Andreas Widl, Kai Zhou  
                <br>
                <em><strong>SIGKDD 2024</strong></em> | <strong>CCF: A</strong> |
                <a style="color: #447ec9" href="https://doi.org/10.1145/3637528.3671610">Paper</a> | 
                <a style="color: #447ec9" href="https://github.com/CavitationDetection/HKG">Code</a>
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">The paper explores hierarchical Knowledge of labels with GCN.</li>
                <li style="margin-left: 10px;">The paper presents the Hierarchical Knowledge Correlation Matrix.</li>
                <li style="margin-left: 10px;">The sound cavitation datasets provided by SAMSON AG.</li>
              </ul>
            </div>
          </div>

        <!-- 10 -->
          <!-- ÈöêÂΩ¢ÁôΩÁ∫ø -->
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    ESWA 2024
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/ESWA2024.png' alt="sym" width="370" height="180" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>Hierarchical Cavitation Intensity Recognition Using Sub-Master Transition Network-based Acoustic Signals in Pipeline Systems</strong>
                <br>
                Shuiping Gou, <strong>Yu Sha*</strong>, Bo Liu, Ningtao Liu, Johannes Faber, Stefan Schramm, Horst Stoecker, Thomas Steckenreiter, Domagoj Vnucec, Nadine Wetzstein, Andreas Widl, Kai Zhou
                <br>
                <em><strong>Expert Systems with Applications</strong></em> | 2024 |<strong>SCI: 1-Top</strong> |
                <a style="color: #447ec9" href="https://www.sciencedirect.com/science/article/pii/S0957417424020220?via%3Dihub">Paper</a>
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">The paper presents a two-stage hierarchical classification network</li>
                <li style="margin-left: 10px;">The paper proposes a hierarchical label tree.</li>
                <li style="margin-left: 10px;">The sound cavitation datasets provided by SAMSON AG.</li>
              </ul>
            </div>
          </div>
        </div>

        <!-- 9 -->
        <div class="container">
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    KDD 2022 (Poster)
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/KDD2022.png' alt="sym" width="370" height="180" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>Regional-Local Adversarially Learned One-Class Classifier Anomalous Sound Detection in Global Long-Term Space</strong>
                <br>
                <strong>Yu Sha</strong>, Shuiping Gou, Johannes Faber, Bo Liu, Wei Li, Stefan Schramm, Horst Stoecker, Thomas Steckenreiter, Domagoj Vnucec, Nadine Wetzstein, Andreas Widl, Kai Zhou  
                <br>
                <em><strong>SIGKDD 2022</strong></em> | <strong>CCF: A</strong> |
                <a style="color: #447ec9" href="https://dl.acm.org/doi/abs/10.1145/3534678.3539133">Paper</a> | 
                <a style="color: #447ec9" href="https://github.com/CavitationDetection/GRLNet">Code</a>
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">The paper proposes a global filter layer based on a 1D FFT global filter for long-term interactions.</li>
                <li style="margin-left: 10px;">The paper extends the capability of discriminating real against fake signals to differentiating between local and regional reconstructions.</li>
                <li style="margin-left: 10px;">The paper designs a novel balanceable detection strategy.</li>
              </ul>
            </div>
          </div>

        <!-- 8 -->
        <div class="container">
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    EAAI 2022
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/EAAI2022.png' alt="sym" width="370" height="150" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>A multi-task learning for cavitation detection and cavitation intensity recognition of valve acoustic signals</strong>
                <br>
                <strong>Yu Sha</strong>, Johannes Faber, Shuiping Gou, Bo Liu, Wei Li, Stefan Schramm, Horst Stoecker, Thomas Steckenreiter, Domagoj Vnucec, Nadine Wetzstein, Andreas Widl, Kai Zhou 
                <br>
                <em><strong>Engineering Applications of Artificial Intelligence</strong></em> | 2022 | <strong>SCI: 1-Top</strong> |
                <a style="color: #447ec9" href="https://dl.acm.org/doi/abs/10.1145/3534678.3539133">Paper</a> | 
                <a style="color: #447ec9" href="https://github.com/CavitationDetection/GRLNet">Code</a>
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">The paper regards cavitation detection and cavitation intensity recognition as a multi-task learning.</li>
                <li style="margin-left: 10px;">The 1-D Double Hierarchical Residual Blocks with large kernel are proposed as an automatic feature extractor.</li>
                <li style="margin-left: 10px;">The sound cavitation datasets provided by SAMSON AG.</li>
              </ul>
            </div>
          </div>

        <!-- 7 -->
        <div class="container">
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    Measurement 2022
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/Measurement2022.png' alt="sym" width="370" height="220" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>An acoustic signal cavitation detection framework based on XGBoost with adaptive selection feature engineering</strong>
                <br>
                <strong>Yu Sha</strong>, Johannes Faber, Shuiping Gou, Bo Liu, Wei Li, Stefan Schramm, Horst Stoecker, Thomas Steckenreiter, Domagoj Vnucec, Nadine Wetzstein, Andreas Widl, Kai Zhou
                <br>
                <em><strong>Measurement</strong></em> | 2022 | <strong>SCI: 2-Top</strong> |
                <a style="color: #447ec9" href="https://www.sciencedirect.com/science/article/pii/S0263224122001798">Paper</a> | 
                <a style="color: #447ec9" href="https://github.com/CavitationDetection/XGBoost_ASFE">Code</a>
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">The paper proposes a adaptive feature aggregation module.</li>
                <li style="margin-left: 10px;">The paper presents a adaptive feature crosses module.</li>
                <li style="margin-left: 10px;">The sound cavitation datasets provided by SAMSON AG.</li>
              </ul>
            </div>
          </div>

        <!-- 10 -->
          <!-- ÈöêÂΩ¢ÁôΩÁ∫ø -->
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    Front. Neurosci. 2025
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/FontNeusc.png' alt="sym" width="370" height="180" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>Dynamic Spatio-Temporal Pruning for Efficient Spiking Neural Networks</strong>
                <br>
                Shuiping Gou, Jiahui Fu, <strong>Yu Sha</strong>, Zhen Cao, Zhang Guo, Jason K. Eshraghian, Ruimin Li, Licheng Jiao  
                <br>
                <em><strong>Frontiers in Neuroscience</strong></em> | 2025 |<strong>SCI: 2-Top</strong> |
                <a style="color: #447ec9" href="https://www.frontiersin.org/journals/neuroscience">Paper</a>
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">A spatio-temporal pruning algorithm is proposed to reduce the temporal redundancy,</li>
                <li style="margin-left: 10px;">Spatial pruning leverages global and inter-layer parameter statistics to minimize model degradation under extreme sparsity.</li>
              </ul>
            </div>
          </div>
        </div>

          
  
        <!-- 10 -->
          <!-- ÈöêÂΩ¢ÁôΩÁ∫ø -->
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    JBHI 2024
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/JBHI2024.png' alt="sym" width="370" height="180" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>Self-supervised, Non-Contact Heartbeat Detection Based on Ballistocardiograms utilizing Physiological Information Guidance</strong>
                <br>
                Changezhe Jiao, Aoyu Yang, Hantao Zhao, Ruhan Yi, Shuiping Gou, <strong>Yu Sha</strong>, Wanshun Wen, Licheng Jiao, Marjorie Skubic  
                <br>
                <em><strong>IEEE Journal of Biomedical and Health Informatics</strong></em> | 2024 |<strong>SCI: 1-Top</strong> |
                <a style="color: #447ec9" href="https://ieeexplore.ieee.org/document/10810416/authors#authors">Paper</a>
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">A non-contact, self-supervised heart rate detection method based on physiological information,</li>
                <li style="margin-left: 10px;">The paper proposes a heartbeat mapping algorithm based on Bidirectional Long Short-Term Memory Network.</li>
              </ul>
            </div>
          </div>
        </div>
        <!-- 6 -->
        <div class="container">
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    MIR 2023
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/MIR2023.png' alt="sym" width="370" height="150" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>Prioritization Hindsight Experience based on Spatial Position Attention for Robots</strong>
                <br>
                Ye Yuan, <strong>Yu Sha</strong>, Feixiang Sun, Haofan Lu, Shuiping Gou, Jie Luo 
                <br>
                <em><strong>Machine Intelligence Research</strong></em> | 2025 | <strong>SCI: 2</strong> |
                <a style="color: #447ec9" href="https://link.springer.com/article/10.1007/s11633-023-1467-z">Paper</a> 
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">The paper proposes a spatial position attention module for the existing HER framework.</li>
                <li style="margin-left: 10px;">The paper presents a theoretical analysis of the total spatial position distance of manipulated object.</li>
                <li style="margin-left: 10px;">Eight robotic manipulation tasks in the Fetch and Hand robot environments of OpenAI Gym.</li>
              </ul>
            </div>
          </div>

        <!-- 5 -->
        <div class="container">
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    DH3D 2022
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/DH3D2022.png' alt="sym" width="370" height="150" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>Phase Retrieval for Terahertz Holography with Physics-Informed Deep Learning</strong>
                <br>
                Mingjun Xiang, Lingxiao Wang, <strong>Yu Sha</strong>, Hui Yuan, Kai Zhou, Hartmut G Roskos
                <br>
                <em><strong>Digital Holography and Three-Dimensional Imaging</strong></em> | 2022 | <strong>EI</strong> |
                <a style="color: #447ec9" href="https://link.springer.com/journal/11633">Paper</a>  
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">The paper proposes a two novel phase retrieval methods for THz holography.</li>
                <li style="margin-left: 10px;">The paper employs unsupervised learning and supervised learning based on the MNIST dataset.</li>
              </ul>
            </div>
          </div>
        
        <!-- 4 -->
        <div class="container">
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    AIIG 2022
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/AIIG2022.png' alt="sym" width="370" height="180" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>A study on small magnitude seismic phase identification using 1D deep residual neural network</strong>
                <br>
                Wei Li, Megha Chakraborty, <strong>Yu Sha</strong>, Kai Zhou, Johannes Faber, Georg R√ºmpker, Horst St√∂cker, Nishtha Srivastava
                <br>
                <em><strong>Artificial Intelligence in Geosciences</strong></em> | 2022 | <strong>SCI: 2</strong> |
                <a style="color: #447ec9" href="https://www.sciencedirect.com/science/article/pii/S2666544122000284">Paper</a> | 
                <a style="color: #447ec9" href="https://github.com/srivastavaresearchgroup/Seismic-phase-Classification">Code</a>
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">1D deep Residual Neural Network for tackling the problem of seismic signal detection and phase identification.</li>
                <li style="margin-left: 10px;">The method is trained and tested on the dataset recorded by the Southern California Seismic Network.</li>
                <li style="margin-left: 10px;">The model generalizability is also tested further on the STanford EArthquake Dataset.</li>
              </ul>
            </div>
          </div>
        

        <!-- 3 -->
        <p>
          <li><strong>Deep Learning-based Small Magnitude Earthquake Detection and Seismic Phase Classification</strong>
          <br>
          Wei Li, <strong>Yu Sha</strong>, Kai Zhou, Johannes Faber, Georg R√ºmpker, Horst St√∂cker, Nishtha Srivastava
          <br>
          <em>arXiv</em> 2204.02870 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2204.02870.pdf">Paper</a> | <a style="color: #447ec9" href="https://github.com/srivastavaresearchgroup/Seismic-phase-Classification">Code</a>
        </p>

        <!-- 2 -->
        <p>
          <li><strong>Smart home system based on STC89C52</strong>
          <br>
          Liang Qin, <strong>Yu Sha</strong>, Yumeng Xu
          <br>
          <em>Practical Electronics</em> | 2018 | <a style="color: #447ec9" href="http://www.cqvip.com/qk/97913x/201803/674492691.html">Paper</a>
        </p>

        <!-- 1 -->
        <p>
          <li><strong>Study on operation analysis and decision making for sharing-bicycles</strong>
          <br>
          Hong Zhang, Dixin Zhou, Chuanqi Cheng, <strong>Yu Sha</strong> 
          <br>
          <em>Big Data Research</em> | 2019 | <a style="color: #447ec9" href="http://www.infocomm-journal.com/bdr/CN/Y2019/V5/I1/87">Paper</a>
        </p>
      </ol>

    <h4> Patents:</h4>
    <ol>
      <p>
        <li><strong>Heart rate estimation method based on cross-modal mapping of heart impact map signals</strong>
        <br>
        Shuiping Gou, Yuanjie Liu, Ningtao Liu, <strong>Yu Sha</strong>, Changzhe Jiao, Dong Hai, Shasha Mao, Jiaxin Cheng
        <br>
        <em>Invention Patent</em> | CN111887858B | </a>
      </p>
      
      <p>
        <li><strong>Hierarchical Cavitation Intensity Recognition Using Sub-Master Transition Network-based Acoustic Signals in Pipeline Systems</strong>
        <br>
        Shuiping Gou, <strong>Yu Sha</strong>, Zhang Guo, Bo Liu
        <br>
        <em>Invention Patent</em> | 202310945885.1 | </a>
      </p>
      
      <p>
        <li><strong>Face Aging Method Based on Adversarial Learning of Local and Global Region Policies</strong>
        <br>
        Shuiping Gou, Ruichen Xue, Nuo Tong, Ruimin Li, <strong>Yu Sha</strong>, Ningtao Liu
        <br>
        <em>Invention Patent</em> | 202310941541.3 |</a>
      </p>

      <p>
        <li><strong>Physics-Guided Global Filtering Attention Convolutional Neural Networks for Image Classification</strong>
        <br>
        Zhang Guo, Huiyu Chen, Shuiping Gou, <strong>Yu Sha</strong>, Xinlin Wang,  Bo Liu
        <br>
        <em>Invention Patent</em> | 202411474637.4 |</a>
      </p>
      
    </ol>
</div>

<!-- The Projects Section -->
<div class="w3-container w3-padding-32" id="projects">
  <h2>üß∞ Projects</h2>
  <h4> Xidian University (XDU):</h4>
  <ol>
    <p>
      <li><strong>Analysis of battlefield situation of artificial intelligence in the context of big data</strong>
      <br>
      <em>The 20th Research Institute of China Electronics Technology Group Corporation-Xidian Joint Laboratory for Artificial Intelligence</em> | <strong>Completed</strong> | <strong>Project Participant</strong>
      <br>    
    </p>

    <p>
      <li><strong>Knee intensity recognition for smart wearable devices based on machine learning</strong>
      <br>
      <em>Xijing Hospital</em> | <strong>Completed</strong> | <strong>Project Participant</strong>
      <br>    
    </p>
  </ol>

  <h4>Frankfurt Institute for Advanced Studies (FIAS):</h4>
  <ol>
    <p>
      <li><strong>Cavitation and leakage detection in large pump/pipe using AI method</strong>
      <br>
      <em>SAMSON AG</em> | <strong>Completed</strong> | <strong>Project Participant</strong>
      <br>    
    </p>
  </ol>

  <h4>Lanzhou University of Technology (LUT):</h4>
  <ol>
    <p>
      <li><strong>LoRa based non-contact life detection system</strong>
      <br>
      <em>National Undergraduate Innovation and Entrepreneurship Training Project</em> | <strong>Completed</strong> | <strong>Project Participant</strong>
      <br>    
    </p>

    <p>
      <li><strong>Evaluation of students' comprehensive ability and program design based on fuzzy theory</strong>
      <br>
      <em>LUT Innovation and Entrepreneurship Training Program</em> | <strong>Completed</strong> | <strong>Project Leader</strong>
      <br>    
    </p>

    <p>
      <li><strong>Research on the cultivation of college students' creative ability by mathematical modeling competition</strong>
      <br>
      <em>LUT Technology Innovation Fund</em> | <strong>Completed</strong> | <strong>Project Participant</strong>
      <br>    
    </p>

    <p>
      <li><strong>WeChat program design for second-hand transaction and donation platform on campus</strong>
      <br>
      <em>LUT Technology Innovation Fund</em> | <strong>Completed</strong> | <strong>Project Participant</strong>
      <br>    
    </p>
  </ol>
  
<!-- The Awards Section -->
  <div class="w3-container w3-padding-32" id="award">
    <h2>üèÜ Awards</h2>
    <h4> Xidian University (XDU):</h4>    
    <p><li> <em>2025</em>, Outstanding Graduate Doctoral Student, XDU</p>
    <p><li> <em>2022</em>, Outstanding Doctoral Students, XDU</p>
    <p><li> <em>2022</em>, Graduate Student Academic Scholarships (First Level), XDU</p>
    <p><li> <em>2021</em>, Outstanding Doctoral Students, XDU</p>
    <p><li> <em>2021</em>, Graduate Student Academic Scholarships (Second Level), XDU</p>
    <p><li> <em>2021</em>, OGB Large-Scale Challenge, KDD Cup 2021, Team Name: <strong>yfishlab</strong>, World Ranking: <strong>Top 48</strong></p>
    <p><li> <em>2020</em>, Outstanding Doctoral Students, XDU</p>
    <p><li> <em>2020</em>, Graduate Student Academic Scholarships (Second Level), XDU</p>
    <p><li> <em>2020</em>, ZhiPu AI: COVID-19 Prediction, <strong>Top 7</strong>
    <p><li> <em>2020</em>, iFLYTEK Algorithm Competition: Temperature Prediction Challenge, Team Name: <strong>San Ren Xing</strong>, <strong>Top 5</strong>, </p>

    <h4> Lanzhou University of Technology Technology (LUT):</h4>
    <p><li> <em>2019</em>, Outstanding Graduates Awards, LUT</p>
    <p><li> <em>2018</em>, Meritorious Winner of Mathematical Contest in Modeling (MCM/ICM)</p>
    <p><li> <em>2018</em>, First Prize in the 8th MathorCup College Student Mathematical Modeling Challenge</p>
    <p><li> <em>2018</em>, First Prize in the 6th Teddy Cup Data Mining Challenge Competition</p>
    <p><li> <em>2018</em>, Pacemaker to Merit Student, LUT</p>
    <p><li> <em>2017</em>, First Prize of 2017 China Cup ¬∑ Science and Technology Innovation Contest</p>
    <p><li> <em>2017</em>, Second Prize in 2017 Asia and Pacific Mathematical Contest in Modeling</p>
    <p><li> <em>2017</em>, First Prize of Gansu Division in 2017 National College Mathematical Modeling Contest of Higher Education Cup</p>
    <p><li> <em>2017</em>, Third Prize in the 7th MathorCup College Student Mathematical Modeling Challenge</p>
    <p><li> <em>2017</em>, Merit Student, LUT</p>
    <p><li> <em>2017</em>, Merit Student, Gansu Province</p>
    <p><li> <em>2017</em>, National Encouragement Scholarship</p>
    <p><li> <em>2016</em>, National Encouragement Scholarship</p>
  </div>  

<div class="w3-light-grey w3-center w3-padding-24">

  No.
  <script type="text/javascript">
  var sc_project=12881779; 
  var sc_invisible=0; 
  var sc_security="9a565db4"; 
  var sc_https=1; 
  var scJsHost = "https://";
  document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
  "statcounter.com/counter/counter.js'></"+"script>");
  </script> Visitor Since May 2023. Powered by <a href="https://www.w3schools.com/w3css/default.asp" title="W3.CSS" target="_blank" class="w3-hover-opacity">w3.css</a>
  <noscript><div class="statcounter"><a title="Web Analytics Made Easy - StatCounter" href="https://statcounter.com/" target="_blank"><img
  class="statcounter" src="https://c.statcounter.com/12881779/0/9a565db4/0/"
  alt="Web Analytics Made Easy - StatCounter"></a></div>
  </noscript>
  <!-- End of Statcounter Code -->

  </div>

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
